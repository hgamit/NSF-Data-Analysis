{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7ga2OGQC220"
   },
   "source": [
    "# Natural Language Processing using Doc2Vec on National Science Foundation Awards Abstracts\n",
    "---\n",
    "### Team:  \n",
    "Jacob Noble  \n",
    "Himanshu Gamit  \n",
    "Shantanu Hadap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdOYaCrjC22-"
   },
   "source": [
    "### Imports\n",
    "\n",
    "sklearn's Standard Scaler should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12pVWFUTC22_"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler # Replace with SAS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "HiqBFGEx4kNQ",
    "outputId": "58d14eed-d673-4e2a-ec67-237da63a72aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-15 20:28:03--  https://nsfdata.s3.amazonaws.com/nsfdataset.zip\n",
      "Resolving nsfdata.s3.amazonaws.com (nsfdata.s3.amazonaws.com)... 52.216.92.107\n",
      "Connecting to nsfdata.s3.amazonaws.com (nsfdata.s3.amazonaws.com)|52.216.92.107|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 358656602 (342M) [application/zip]\n",
      "Saving to: ‘nsfdataset.zip’\n",
      "\n",
      "nsfdataset.zip      100%[===================>] 342.04M  48.5MB/s    in 7.5s    \n",
      "\n",
      "2020-04-15 20:28:11 (45.7 MB/s) - ‘nsfdataset.zip’ saved [358656602/358656602]\n",
      "\n",
      "Archive:  nsfdataset.zip\n",
      "  inflating: data/nsf_proposals.csv  \n"
     ]
    }
   ],
   "source": [
    "!wget https://nsfdata.s3.amazonaws.com/nsfdataset.zip\n",
    "!unzip nsfdataset.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ELme3JwFr579",
    "outputId": "526f9924-87bd-42a9-94c9-95d63c165af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Projects:  329321 \n",
      "Total Features:  2\n"
     ]
    }
   ],
   "source": [
    "#import saspy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "selected_cols = ['abstractText','date']\n",
    "projects = pd.read_csv(\"data/nsf_proposals.csv\", usecols = selected_cols, low_memory=False) #, nrows=30000\n",
    "print (\"Total Projects: \", projects.shape[0], \"\\nTotal Features: \", projects.shape[1])\n",
    "projects.date = pd.to_datetime(projects.date.str.replace('D', 'T'))\n",
    "projects = projects.sort_values('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPmscOBnC23B"
   },
   "source": [
    "### Load in Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "id": "WpMB6ablC23C",
    "outputId": "6f8e04ad-606d-4c18-8406-b03fced9b311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of the abstractText: 8166\n",
      "Min length of the abstractText: 1\n",
      "Avg length of the abstractText: 1645.861842268939\n",
      "Max words abstractText: 1252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstractText</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295988</th>\n",
       "      <td>Nondestructive Evaluation (NDE) is important t...</td>\n",
       "      <td>1985-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307099</th>\n",
       "      <td>An Industry/University Cooperative Research Ce...</td>\n",
       "      <td>1985-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284877</th>\n",
       "      <td>This research seeks to obtain a representation...</td>\n",
       "      <td>1985-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177779</th>\n",
       "      <td>This is an attempt to develop a \"solvated elec...</td>\n",
       "      <td>1986-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166668</th>\n",
       "      <td>The New York State College of Ceramics at Alfr...</td>\n",
       "      <td>1986-06-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             abstractText       date\n",
       "295988  Nondestructive Evaluation (NDE) is important t... 1985-08-30\n",
       "307099  An Industry/University Cooperative Research Ce... 1985-08-30\n",
       "284877  This research seeks to obtain a representation... 1985-09-06\n",
       "177779  This is an attempt to develop a \"solvated elec... 1986-01-16\n",
       "166668  The New York State College of Ceramics at Alfr... 1986-06-03"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop values without Abstract texts\n",
    "projects = projects.dropna(how='any')\n",
    "\n",
    "print(\"Max length of the abstractText:\", projects.abstractText.str.len().max())\n",
    "print(\"Min length of the abstractText:\", projects.abstractText.str.len().min())\n",
    "print(\"Avg length of the abstractText:\", projects.abstractText.apply(lambda x: len(x) - x.count(\" \")).mean())\n",
    "\n",
    "words = projects.abstractText.str.split().apply(len)\n",
    "print(\"Max words abstractText:\", words.max())\n",
    "projects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJJZRTyCC23F"
   },
   "source": [
    "### Setup Training Set for Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "puEINuT5C23F",
    "outputId": "f47a73f8-5476-411a-e574-540c63063787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts:  321560\n"
     ]
    }
   ],
   "source": [
    "X_raw = projects.abstractText.str.lower().values\n",
    "num_of_docs = len(X_raw)\n",
    "print('Number of abstracts: ', num_of_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ru1PXGUC23J"
   },
   "source": [
    "### Create generator that will tokenize the training abstracts on the fly to save on memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1pg5829C23K"
   },
   "outputs": [],
   "source": [
    "def doc_generator(input_docs_array):\n",
    "    for i, doc in enumerate(input_docs_array):\n",
    "        tokens = gensim.utils.simple_preprocess(doc)\n",
    "        yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7ZvV6OTC23Q"
   },
   "outputs": [],
   "source": [
    "X = doc_generator(X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHy9VORiC23V"
   },
   "source": [
    "### Create Initial Doc2Vec Model and Training\n",
    "\n",
    "#### Skip to next section to work load in a pretrained model.  Training could take a potentially long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArrJv_dvC23W"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import multiprocessing\n",
    "# from pprint import pprint\n",
    "# cores = multiprocessing.cpu_count()\n",
    "\n",
    "# models = [\n",
    "#     # PV-DBOW \n",
    "#     Doc2Vec(dm=0, dbow_words=1, size=300, window=8, min_count=1, iter=100, workers=cores),\n",
    "#     # PV-DM w/average\n",
    "#     Doc2Vec(dm=1, dm_mean=1, size=300, window=8, min_count=1, iter =100, workers=cores),\n",
    "# ]\n",
    "\n",
    "# models[0].build_vocab(doc_generator(X_raw))\n",
    "# print(str(models[0]))\n",
    "# models[1].reset_from(models[0])\n",
    "# print(str(models[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5QCW4n32P7-"
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "# for i, model in enumerate(models):\n",
    "#     model.train(doc_generator(X_raw), total_examples=len(X_raw), epochs=model.iter)\n",
    "#     model.save(str(i)+'New_nsf_doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BS4x08Y4T-_"
   },
   "outputs": [],
   "source": [
    "# model.docvecs.vectors_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mr5BKOvDC23c"
   },
   "outputs": [],
   "source": [
    "# model.train(doc_generator(X_raw), total_examples=num_of_docs, epochs=1)\n",
    "# model.save('nsf_doc2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gs7Qc0KOC23h"
   },
   "source": [
    "### Load Existing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "hJbB9-JzC23k",
    "outputId": "22c2275e-4207-403e-8ce2-0eaaa6edf60e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "existing_model = 'nsf_d2v_100.model' # Name of Existing model to load\n",
    "model = gensim.models.Doc2Vec.load(str(existing_model)) # Model is assumed to be in the shared folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "slapVISDC23n"
   },
   "source": [
    "### Testing Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "D4T1hmbghnFx",
    "outputId": "f13ae3bb-5055-41d2-daa7-97bed6ddec1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This study utilizes publicly available data from the National Science Foundation (NSF) Web Application Programming Interface (API). In this paper, various machine learning techniques are demonstrated to explore, analyze and recommend similar proposal abstracts to aid the NSF or Awardee with the Merit Review Process. These techniques extract textual context and group it with similar context. The goal of the analysis was to utilize a Doc2Vec unsupervised learning algorithms to embed NSF funding proposal abstracts text into vector space.  Once vectorized, the abstracts were grouped together using K-means clustering. These techniques together proved to be successful at grouping similar proposals together and could be used to find similar proposals to newly submitted NSF funding proposals. To perform text analysis, SAS® University Edition is used which supports SASPy, SAS® Studio and Python JupyterLab. Gensim Doc2vec is used to generate document vectors for proposal abstracts. Afterwards, document vectors were used to cluster similar abstracts using SAS® Studio KMeans Clustering Module. For visualization, the abstract embeddings were reduced to two dimensions using Principal Component Analysis (PCA) within SAS® Studio. This was then compared to a t-Distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction technique as part of the Scikit-learn machine learning toolkit for Python.Conclusively, NSF proposal abstract text analysis can help an awardee read and improve their proposal model by identifying similar proposal abstracts from the last 24 years. It could also help NSF evaluators identify similar existing proposals that indirectly provides insights on whether a new proposal is going to be fruitful or not.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"This study utilizes publicly available data from the National Science Foundation (NSF) Web Application Programming Interface (API). In this paper, various machine learning techniques are demonstrated to explore, analyze and recommend similar proposal abstracts to aid the NSF or Awardee with the Merit Review Process. These techniques extract textual context and group it with similar context. The goal of the analysis was to utilize a Doc2Vec unsupervised learning algorithms to embed NSF funding proposal abstracts text into vector space.  Once vectorized, the abstracts were grouped together using K-means clustering. These techniques together proved to be successful at grouping similar proposals together and could be used to find similar proposals to newly submitted NSF funding proposals. To perform text analysis, SAS® University Edition is used which supports SASPy, SAS® Studio and Python JupyterLab. Gensim Doc2vec is used to generate document vectors for proposal abstracts. Afterwards, document vectors were used to cluster similar abstracts using SAS® Studio KMeans Clustering Module. For visualization, the abstract embeddings were reduced to two dimensions using Principal Component Analysis (PCA) within SAS® Studio. This was then compared to a t-Distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction technique as part of the Scikit-learn machine learning toolkit for Python.Conclusively, NSF proposal abstract text analysis can help an awardee read and improve their proposal model by identifying similar proposal abstracts from the last 24 years. It could also help NSF evaluators identify similar existing proposals that indirectly provides insights on whether a new proposal is going to be fruitful or not.\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UVA8d2kC23o"
   },
   "outputs": [],
   "source": [
    "test_vector = model.infer_vector(gensim.utils.simple_preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "woPjuZXDC23s",
    "outputId": "0218ede5-7850-4b0b-ea6c-1e8ff7c320d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.40085745e+00, -1.14149630e+00,  9.86760318e-01, -1.62086606e+00,\n",
       "        1.42755830e+00, -1.04308939e+00,  7.57398307e-01,  7.10320592e-01,\n",
       "        4.35654730e-01, -6.89626532e-03,  2.37417603e+00,  3.77059531e+00,\n",
       "        2.33537984e+00,  1.54080391e-01, -5.34181595e-01, -1.64020312e+00,\n",
       "       -5.56470789e-02, -1.47133923e+00, -7.56075680e-02, -8.01131248e-01,\n",
       "       -3.72663260e+00, -1.56961095e+00,  1.13951278e+00,  3.87071043e-01,\n",
       "        9.35525373e-02,  1.49220622e+00, -4.79168594e-01, -1.82896674e+00,\n",
       "        2.15608788e+00,  7.90614605e-01,  6.88332319e-01, -2.58386111e+00,\n",
       "        2.04685712e+00,  7.56009459e-01, -7.70424485e-01,  1.54531622e+00,\n",
       "       -9.00842607e-01, -2.23787022e+00,  1.88065755e+00,  1.21908095e-02,\n",
       "        3.37004691e-01, -1.12742722e+00, -3.59022069e+00,  2.73497081e+00,\n",
       "       -9.36699629e-01,  1.98303711e+00,  5.09007454e-01, -2.09456515e+00,\n",
       "       -1.69952250e+00, -2.63290793e-01, -4.67105448e-01,  7.25143254e-01,\n",
       "       -4.64004904e-01, -1.59350419e+00, -3.60318571e-01, -3.26127708e-01,\n",
       "        1.44056559e+00, -2.79561400e+00,  7.78587878e-01, -3.71829093e-01,\n",
       "       -2.97428966e+00,  2.53411722e+00,  2.13354540e+00, -4.93608564e-01,\n",
       "        5.14984548e-01, -9.61637676e-01, -5.92562973e-01, -9.85217929e-01,\n",
       "       -6.49218559e-01,  7.56930947e-01,  2.15879411e-01,  2.32754970e+00,\n",
       "        3.92454296e-01,  6.91523969e-01,  1.54138517e+00, -1.42006016e+00,\n",
       "       -1.12733519e+00, -9.92085397e-01,  2.70809501e-01,  7.08127439e-01,\n",
       "       -4.04367834e-01, -1.84388113e+00,  2.52830267e+00, -6.72715366e-01,\n",
       "       -5.10539472e-01,  6.97602928e-01,  8.93175721e-01, -3.88249844e-01,\n",
       "        2.04630160e+00,  9.58461225e-01,  5.02901733e-01,  2.16161460e-02,\n",
       "        1.44418001e+00, -1.63790250e+00, -3.99071157e-01, -2.38486484e-01,\n",
       "       -1.26725566e+00, -8.52701426e-01, -8.78998518e-01, -1.45979181e-01,\n",
       "        1.01510681e-01, -1.36839941e-01,  1.86290419e+00,  1.99133229e+00,\n",
       "        1.44742334e+00, -6.68794274e-01, -7.21529424e-01, -1.13023400e+00,\n",
       "        1.48142612e+00, -2.72344661e+00, -6.07899688e-02, -1.96958292e+00,\n",
       "        7.04003572e-01, -3.12964296e+00, -6.46577701e-02,  7.19840825e-01,\n",
       "       -1.74929571e+00, -5.46987534e-01,  3.29928637e+00, -6.50296092e-01,\n",
       "       -3.39574039e-01,  5.81575394e-01,  8.24442208e-01,  2.08920836e-02,\n",
       "        6.64118648e-01, -2.50256824e+00, -2.90697843e-01, -2.42636800e+00,\n",
       "        3.87456745e-01,  1.21843171e+00, -2.90155619e-01, -2.07039252e-01,\n",
       "       -1.22462988e+00, -1.02585733e+00, -1.29946411e+00, -5.31506360e-01,\n",
       "       -7.56718040e-01, -1.90331841e+00, -1.97571218e+00,  1.24171412e+00,\n",
       "       -5.32802701e-01, -1.06095469e+00,  2.14903988e-03,  6.58005595e-01,\n",
       "        8.11731219e-01,  1.88592464e-01, -1.72243428e+00, -4.05566072e+00,\n",
       "       -7.24547923e-01, -1.65597820e+00, -1.02434838e+00,  2.33150885e-01,\n",
       "        6.40783310e-01, -1.92940700e+00,  3.82654518e-01, -4.60533977e-01,\n",
       "        5.16829133e-01,  1.52870595e+00, -3.24056292e+00, -7.75512874e-01,\n",
       "       -6.96090996e-01, -1.24241784e-01, -1.05998385e+00,  6.11104369e-01,\n",
       "       -1.09531546e+00, -1.48674738e+00, -2.52530426e-01, -1.19580768e-01,\n",
       "       -2.62503576e+00,  1.03785968e+00, -1.84066808e+00,  4.13668871e-01,\n",
       "       -1.79569101e+00,  3.13180268e-01,  5.16641364e-02, -1.18321359e+00,\n",
       "        4.30147350e-01, -9.07013714e-01, -3.15302396e+00,  4.99664068e-01,\n",
       "        1.13906607e-01,  5.81738114e-01,  1.62647212e+00, -1.29882896e+00,\n",
       "        1.47750866e+00, -1.92477131e+00,  3.24602783e-01,  4.03835671e-03,\n",
       "        3.24083090e+00, -1.90436649e+00, -1.00218213e+00, -1.25903577e-01,\n",
       "       -4.77061152e-01,  2.77634352e-01,  1.94320053e-01, -2.45087314e+00,\n",
       "        4.32770777e+00, -1.79712248e+00, -1.52160680e+00, -4.95041639e-01,\n",
       "       -1.91135466e+00,  1.02101600e+00, -2.89935708e+00, -3.27632688e-02,\n",
       "        7.90581644e-01,  2.12798834e+00,  1.59074175e+00, -4.01886962e-02,\n",
       "        1.39567888e+00, -1.40651548e+00, -1.67043352e+00, -2.02067566e+00,\n",
       "        1.76058519e+00,  1.24334745e-01, -1.06162250e-01, -9.95651931e-02,\n",
       "       -1.68038917e+00, -1.41922086e-01, -4.99524802e-01,  4.72083837e-01,\n",
       "        7.36167729e-01,  1.44526839e+00, -7.52253294e-01, -5.81543088e-01,\n",
       "       -4.92445752e-02,  5.30992091e-01, -1.68909639e-01,  2.19181347e+00,\n",
       "        1.73951471e+00, -2.36723161e+00,  8.04155171e-02, -1.37819242e+00,\n",
       "        2.56290698e+00, -1.38500357e+00, -3.26424003e-01, -7.05208421e-01,\n",
       "        6.39793694e-01, -1.37935424e+00,  7.78398454e-01,  1.41174304e+00,\n",
       "        1.11275518e+00,  1.84232140e+00,  1.26912105e+00,  4.77458209e-01,\n",
       "       -5.43401957e-01,  6.05436563e-01,  1.86932600e+00, -5.42207003e-01,\n",
       "       -1.57669520e+00, -1.31430149e+00,  1.90273002e-01, -1.42163205e+00,\n",
       "       -1.81967556e+00, -5.54371774e-01, -1.32380974e+00, -1.09310162e+00,\n",
       "        7.54771888e-01, -9.45669770e-01, -2.47624755e+00,  1.64662647e+00,\n",
       "       -1.16568279e+00,  1.18896544e+00, -7.17133164e-01, -1.11860320e-01,\n",
       "        4.04581457e-01,  2.67314047e-01,  8.41284573e-01, -4.06394213e-01,\n",
       "       -8.27135742e-02, -3.24673563e-01,  1.17925489e+00, -1.05053592e+00,\n",
       "        4.37563241e-01,  1.27588356e+00,  1.42312860e+00,  1.86090314e+00,\n",
       "       -5.88840619e-02,  2.69286603e-01,  1.07847214e+00,  1.07887793e+00,\n",
       "       -3.23197746e+00,  2.05843240e-01,  1.16098380e+00, -2.01068401e+00,\n",
       "       -5.90152219e-02, -1.80126846e-01, -1.15692258e+00,  1.46284497e+00,\n",
       "       -7.47299314e-01, -1.41473562e-01, -1.87884533e+00, -3.37005287e-01,\n",
       "        8.97602923e-03, -1.90778327e+00, -7.16694891e-01,  3.99931860e+00,\n",
       "       -9.26124811e-01, -1.20195067e+00, -8.63054514e-01, -2.41715527e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "MZ8dZDfPC23v",
    "outputId": "c4b1455d-dea0-4bd8-fd2b-4e4b6c83f828"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(289674, 0.3379325568675995),\n",
       " (258922, 0.3322885036468506),\n",
       " (305430, 0.32162389159202576)]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar(\n",
    "    positive=[test_vector], \n",
    "    topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnnZTNlBIWTT"
   },
   "outputs": [],
   "source": [
    "file = open('top1.txt', 'w',encoding=\"utf-8\")\n",
    "file.write(X_raw[289674])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WX7zmH6oC23y"
   },
   "outputs": [],
   "source": [
    "file = open('top2.txt', 'w',encoding=\"utf-8\")\n",
    "file.write(X_raw[258922])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FWQ2EF8C24H"
   },
   "outputs": [],
   "source": [
    "file = open('top3.txt', 'w',encoding=\"utf-8\")\n",
    "file.write(X_raw[24392])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2G0n0VRaC24J"
   },
   "outputs": [],
   "source": [
    "### Text summerizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjVXD-4jhnGK"
   },
   "source": [
    "### Create the session\n",
    "\n",
    "The session remembers our connection parameters to SageMaker. We'll use it to perform all of our SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "ThbzqpNFkEeS",
    "outputId": "f816d871-9c3b-4244-cc39-d0105cdc2150"
   },
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sage.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTTJoGXrhnGM"
   },
   "source": [
    "## Create Model\n",
    "\n",
    "Now we use the Model Package to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VdfpjcehnGN"
   },
   "outputs": [],
   "source": [
    "# Please use the appropriate ARN obtained after subscribing to the model to define 'model_package_arn'\n",
    "model_package_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/marketplace-text-summarizer-11-d2490248e8de20f24ae3b72d0d74654c'\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sage.Session()\n",
    "model = ModelPackage(model_package_arn=model_package_arn,\n",
    "                    role = role,\n",
    "                    sagemaker_session = sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPPl9wQ-hnGP"
   },
   "source": [
    "## Input File\n",
    "\n",
    "Now we pull a sample input file for testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRE7YW7yhnGQ"
   },
   "outputs": [],
   "source": [
    "top1_txt=\"s3://nsf/top1.txt\"\n",
    "top2_txt=\"s3://nsf/top2.txt\"\n",
    "top3_txt=\"s3://nsf/top3.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7rBN7cQLhnGU"
   },
   "source": [
    "## Batch Transform Job\n",
    "\n",
    "Now let's use the model built to run a batch inference job and verify it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ul_Wsbb1hnGV",
    "outputId": "7d3504fe-061d-4179-c793-350ad57e0cb7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import json \n",
    "# import uuid\n",
    "# transformer = model.transformer(2, 'ml.m5.xlarge')\n",
    "# transformer.output_path = \"s3://nsf/Summerized\"\n",
    "# transformer.transform(top1_txt, content_type='text/plain')\n",
    "# transformer.wait()\n",
    "# print(\"Batch Transform complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YThSIa-ehnGX"
   },
   "source": [
    "## Output from Batch Transform\n",
    "\n",
    "Note: Ensure that the following package is installed on the local system : boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOehVNlDhnGX",
    "outputId": "1dda1784-b3a7-4a4b-9820-955c43c55fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://nsf/Summerized\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "print(transformer.output_path)\n",
    "bucketFolder = transformer.output_path.rsplit('/')[3]\n",
    "#print(s3bucket,s3prefix)\n",
    "s3_conn = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IelofWEDhnGZ",
    "outputId": "c80e27bc-c3be-4fa7-d20c-1cdfb0b48481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "bucket_name=\"nsf\"\n",
    "with open('result.txt', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name,bucketFolder+'/top1.txt.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShU-mX2fhnGb"
   },
   "outputs": [],
   "source": [
    "with open('./result.txt', 'rb') as file_stream:\n",
    "    output_text = file_stream.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2Ydu5tPhnGc"
   },
   "source": [
    "#### Original Text Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lC20mx4MhnGd",
    "outputId": "3bdd6ae8-4deb-49ea-9b68-d04e5aa8062b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This study utilizes publicly available data from the National Science Foundation (NSF) Web Application Programming Interface (API). In this paper, various machine learning techniques are demonstrated to explore, analyze and recommend similar proposal abstracts to aid the NSF or Awardee with the Merit Review Process. These techniques extract textual context and group it with similar context. The goal of the analysis was to utilize a Doc2Vec unsupervised learning algorithms to embed NSF funding proposal abstracts text into vector space.  Once vectorized, the abstracts were grouped together using K-means clustering. These techniques together proved to be successful at grouping similar proposals together and could be used to find similar proposals to newly submitted NSF funding proposals. To perform text analysis, SAS® University Edition is used which supports SASPy, SAS® Studio and Python JupyterLab. Gensim Doc2vec is used to generate document vectors for proposal abstracts. Afterwards, document vectors were used to cluster similar abstracts using SAS® Studio KMeans Clustering Module. For visualization, the abstract embeddings were reduced to two dimensions using Principal Component Analysis (PCA) within SAS® Studio. This was then compared to a t-Distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction technique as part of the Scikit-learn machine learning toolkit for Python.Conclusively, NSF proposal abstract text analysis can help an awardee read and improve their proposal model by identifying similar proposal abstracts from the last 24 years. It could also help NSF evaluators identify similar existing proposals that indirectly provides insights on whether a new proposal is going to be fruitful or not.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UL2o6hDqhnGf"
   },
   "source": [
    "#### Similar abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Fnb5-1ShnGg",
    "outputId": "b86d3fe5-feed-4588-c3e7-33520c8ca5f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "bucket_name=\"nsf\"\n",
    "with open('top1.txt', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name,'top1.txt', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyr6R3KXhnGi"
   },
   "outputs": [],
   "source": [
    "with open('./top1.txt', 'rb') as file_stream:\n",
    "    input_text = file_stream.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "je59I3LQhnGj",
    "outputId": "882fc12a-fead-4bcf-c6cf-6130f0dd9a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this reu site award to auburn university, located in auburn, alabama, will support the training of 10 students for 10 weeks during each summer from 2018-2020. this program is focused on warm-water aquatic ecology and will use the vast biological diversity and many aquatic ecosystems found in the southeastern u.s. as well as the available infrastructure in participating labs to broadly train reu students in core elements of interdisciplinary research, namely establishing hypotheses, experimental design, data interpretation, professional network development, and scientific ethics. reu students will participate in a variety of activities, such as a two-day aquatic ecology course, mentor research seminars, regular mentor-mentee and reu student meetings, student-driven research projects, professional development activities, and field trips.\n",
      "\n",
      "it is anticipated that a total of 30 students, primarily freshman and sophomores from schools with limited research opportunities including community colleges, will be trained in the program. through planned basic and applied research activities, reu students will learn how research is conducted to prepare them for successful careers in academia, industry, and government agencies where they will be equipped to solve existing and imminent environmental challenges related to water. reu students will be supported to publish their research and many will present the results of their work at scientific conferences. to broaden the impact of the reu research projects, all reu students will be encouraged to develop and lead an outreach project involving journalism or art faculty and students.   \n",
      "\n",
      "a common web-based assessment tool used by all reu site programs funded by the division of biological infrastructure will be used to determine the effectiveness of the training program. in addition, weekly assessments will gauge the quality and effectiveness of different components of the program including the research experience, mentors, professional development activities, and housing. students will be tracked for at least five years after the program to determine their career paths. in addition, students will be asked to respond to an automatic email sent via the nsf reporting system. more information about the program is available by visiting http://wilsonlab.com/reu/ or by contacting the pi, dr. alan wilson at wilson@auburn.edu\n"
     ]
    }
   ],
   "source": [
    "print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DyNXd1R8hnGl"
   },
   "source": [
    "#### Summary of similar abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLaDnrJjhnGm",
    "outputId": "563a5a21-492f-42a1-ec89-8de7dbbf2e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This reu site award to auburn university , located in auburn , alabama , will support the training of 10 students for 10 weeks during each summer from 2018-2020. This program is focused on warm-water aquatic ecology and will use the vast biological diversity and many aquatic ecosystems found in the southeastern u. As well as the available infrastructure in participating labs to broadly train reu students in core elements of interdisciplinary research , namely establishing hypotheses , experimental design , data interpretation , professional network development , and scientific ethics. It is anticipated that a total of 30 students , primarily freshman and sophomores from schools with limited research opportunities including community colleges , will be trained in the program. Reu students will participate in a variety of activities , such as a two-day aquatic ecology course , mentor research seminars , regular mentor-mentee and reu student meetings , student-driven research projects , professional development activities , and field trips.\n",
      "Execution time : 1.77seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4aIePLvhnGr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9ymEMqQhnGt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NSFFinal.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}